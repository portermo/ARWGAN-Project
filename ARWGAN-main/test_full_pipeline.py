#!/usr/bin/env python3
"""
å®Œæ•´è¨“ç·´ç®¡ç·šæ¸¬è©¦
æ¸¬è©¦è³‡æ–™è¼‰å…¥ã€æ¨¡å‹åˆå§‹åŒ–ã€forward/backward pass
"""

import torch
import numpy as np
from options import HiDDenConfiguration, TrainingOptions
from model.ARWGAN import ARWGAN
from noise_layers.noiser import Noiser
from noise_layers.jpeg import Jpeg
import utils

def test_data_loader():
    """æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨"""
    print("=" * 60)
    print("æ¸¬è©¦ 1: è³‡æ–™è¼‰å…¥å™¨")
    print("=" * 60)
    
    try:
        net_config = HiDDenConfiguration(
            H=128, W=128,
            message_length=30,
            encoder_blocks=4, encoder_channels=64,
            decoder_blocks=7, decoder_channels=64,
            use_discriminator=True,
            use_vgg=False,
            discriminator_blocks=3, discriminator_channels=64,
            decoder_loss=1,
            encoder_loss=0.7,
            adversarial_loss=1e-3,
            enable_fp16=False
        )
        
        train_options = TrainingOptions(
            batch_size=2,  # å° batch size ç”¨æ–¼æ¸¬è©¦
            number_of_epochs=1,
            train_folder='data/coco2017/train',
            validation_folder='data/coco2017/val',
            runs_folder='./runs',
            start_epoch=1,
            experiment_name='test'
        )
        
        train_loader, val_loader = utils.get_data_loaders(net_config, train_options)
        
        # æ¸¬è©¦è¼‰å…¥ä¸€å€‹ batch
        for images, labels in train_loader:
            print(f"âœ“ è¨“ç·´è³‡æ–™ batch å½¢ç‹€: {images.shape}")
            print(f"âœ“ æ•¸å€¼ç¯„åœ: [{images.min():.4f}, {images.max():.4f}]")
            break
        
        for images, labels in val_loader:
            print(f"âœ“ é©—è­‰è³‡æ–™ batch å½¢ç‹€: {images.shape}")
            break
        
        print("\nâœ… è³‡æ–™è¼‰å…¥å™¨æ¸¬è©¦é€šéï¼\n")
        return net_config, train_options
        
    except Exception as e:
        print(f"\nâŒ è³‡æ–™è¼‰å…¥å™¨æ¸¬è©¦å¤±æ•—: {e}\n")
        import traceback
        traceback.print_exc()
        return None, None


def test_model_initialization(net_config):
    """æ¸¬è©¦æ¨¡å‹åˆå§‹åŒ–"""
    print("=" * 60)
    print("æ¸¬è©¦ 2: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)
    
    try:
        device = torch.device('cpu')  # ä½¿ç”¨ CPU é¿å… GPU ç›¸å®¹æ€§å•é¡Œ
        
        # å»ºç«‹ noiser
        noise_config = [Jpeg(1.0)]
        noiser = Noiser(noise_config, device)
        
        # å»ºç«‹æ¨¡å‹
        model = ARWGAN(net_config, device, noiser, None)
        
        print(f"âœ“ æ¨¡å‹å·²åˆå§‹åŒ–")
        print(f"âœ“ Encoder-Decoder åƒæ•¸æ•¸é‡: {sum(p.numel() for p in model.encoder_decoder.parameters()):,}")
        print(f"âœ“ Discriminator åƒæ•¸æ•¸é‡: {sum(p.numel() for p in model.discriminator.parameters()):,}")
        
        print("\nâœ… æ¨¡å‹åˆå§‹åŒ–æ¸¬è©¦é€šéï¼\n")
        return model, device, noiser
        
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹åˆå§‹åŒ–æ¸¬è©¦å¤±æ•—: {e}\n")
        import traceback
        traceback.print_exc()
        return None, None, None


def test_forward_pass(model, device, net_config):
    """æ¸¬è©¦ forward pass"""
    print("=" * 60)
    print("æ¸¬è©¦ 3: Forward Pass")
    print("=" * 60)
    
    try:
        # å»ºç«‹æ¸¬è©¦è³‡æ–™
        batch_size = 2
        test_image = torch.rand(batch_size, 3, net_config.H, net_config.W).to(device)
        test_message = torch.Tensor(np.random.choice([0, 1], (batch_size, net_config.message_length))).to(device)
        
        # Normalize to [-1, 1]
        test_image = test_image * 2 - 1
        
        print(f"âœ“ è¼¸å…¥åœ–ç‰‡å½¢ç‹€: {test_image.shape}")
        print(f"âœ“ è¼¸å…¥è¨Šæ¯å½¢ç‹€: {test_message.shape}")
        
        # Forward pass (validation mode)
        model.encoder_decoder.eval()
        model.discriminator.eval()
        
        with torch.no_grad():
            losses, (encoded_images, noised_images, decoded_messages) = model.validate_on_batch([test_image, test_message])
        
        print(f"âœ“ ç·¨ç¢¼åœ–ç‰‡å½¢ç‹€: {encoded_images.shape}")
        print(f"âœ“ åŠ å™ªåœ–ç‰‡å½¢ç‹€: {noised_images.shape}")
        print(f"âœ“ è§£ç¢¼è¨Šæ¯å½¢ç‹€: {decoded_messages.shape}")
        
        # æª¢æŸ¥æå¤±
        print("\næå¤±å€¼:")
        for loss_name, loss_value in losses.items():
            print(f"  {loss_name}: {loss_value:.6f}")
        
        # æª¢æŸ¥è¨Šæ¯æº–ç¢ºåº¦
        decoded_rounded = decoded_messages.detach().cpu().numpy().round().clip(0, 1)
        message_detached = test_message.detach().cpu().numpy()
        accuracy = 1 - np.mean(np.abs(decoded_rounded - message_detached))
        print(f"\nâœ“ è¨Šæ¯è§£ç¢¼æº–ç¢ºåº¦: {accuracy*100:.2f}%")
        
        print("\nâœ… Forward pass æ¸¬è©¦é€šéï¼\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ Forward pass æ¸¬è©¦å¤±æ•—: {e}\n")
        import traceback
        traceback.print_exc()
        return False


def test_backward_pass(model, device, net_config):
    """æ¸¬è©¦ backward pass"""
    print("=" * 60)
    print("æ¸¬è©¦ 4: Backward Pass (æ¢¯åº¦è¨ˆç®—)")
    print("=" * 60)
    
    try:
        # å»ºç«‹æ¸¬è©¦è³‡æ–™
        batch_size = 2
        test_image = torch.rand(batch_size, 3, net_config.H, net_config.W).to(device)
        test_message = torch.Tensor(np.random.choice([0, 1], (batch_size, net_config.message_length))).to(device)
        
        # Normalize to [-1, 1]
        test_image = test_image * 2 - 1
        
        # Training mode
        model.encoder_decoder.train()
        model.discriminator.train()
        
        # Forward pass
        losses, _ = model.train_on_batch([test_image, test_message])
        
        print("âœ“ Backward pass å®Œæˆ")
        print("\næå¤±å€¼:")
        for loss_name, loss_value in losses.items():
            print(f"  {loss_name}: {loss_value:.6f}")
        
        # æª¢æŸ¥æ¢¯åº¦
        has_grad = False
        for name, param in model.encoder_decoder.named_parameters():
            if param.grad is not None:
                has_grad = True
                break
        
        if has_grad:
            print("\nâœ“ æ¢¯åº¦å·²è¨ˆç®—")
        else:
            print("\nâš ï¸ è­¦å‘Š: æœªæª¢æ¸¬åˆ°æ¢¯åº¦")
        
        print("\nâœ… Backward pass æ¸¬è©¦é€šéï¼\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ Backward pass æ¸¬è©¦å¤±æ•—: {e}\n")
        import traceback
        traceback.print_exc()
        return False


def test_jpeg_noise(device):
    """æ¸¬è©¦ JPEG å™ªè²å±¤"""
    print("=" * 60)
    print("æ¸¬è©¦ 5: JPEG å™ªè²å±¤")
    print("=" * 60)
    
    try:
        from noise_layers.jpeg import Jpeg, DiffJPEG
        
        # æ¸¬è©¦ DiffJPEG
        diff_jpeg = DiffJPEG(factor=1.0).to(device)
        test_image = torch.rand(2, 3, 128, 128).to(device)
        test_image = torch.clamp(test_image, 0.0, 1.0)
        
        noise_and_cover = [test_image.clone()]
        output = diff_jpeg(noise_and_cover)
        
        print(f"âœ“ DiffJPEG è¼¸å…¥å½¢ç‹€: {test_image.shape}")
        print(f"âœ“ DiffJPEG è¼¸å‡ºå½¢ç‹€: {output[0].shape}")
        print(f"âœ“ è¼¸å‡ºç¯„åœ: [{output[0].min():.4f}, {output[0].max():.4f}]")
        
        # æ¸¬è©¦ Jpeg wrapper
        jpeg = Jpeg(1.0)
        noise_and_cover = [test_image.clone()]
        output = jpeg(noise_and_cover)
        
        print(f"âœ“ Jpeg wrapper æ¸¬è©¦é€šé")
        
        print("\nâœ… JPEG å™ªè²å±¤æ¸¬è©¦é€šéï¼\n")
        return True
        
    except Exception as e:
        print(f"\nâŒ JPEG å™ªè²å±¤æ¸¬è©¦å¤±æ•—: {e}\n")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "=" * 60)
    print("ARWGAN å®Œæ•´ç®¡ç·šæ¸¬è©¦")
    print("=" * 60 + "\n")
    
    results = []
    
    # æ¸¬è©¦ 1: è³‡æ–™è¼‰å…¥
    net_config, train_options = test_data_loader()
    results.append(('è³‡æ–™è¼‰å…¥å™¨', net_config is not None))
    
    if net_config is None:
        print("âŒ ç”±æ–¼è³‡æ–™è¼‰å…¥å¤±æ•—ï¼Œè·³éå¾ŒçºŒæ¸¬è©¦")
        return
    
    # æ¸¬è©¦ 2: æ¨¡å‹åˆå§‹åŒ–
    model, device, noiser = test_model_initialization(net_config)
    results.append(('æ¨¡å‹åˆå§‹åŒ–', model is not None))
    
    if model is None:
        print("âŒ ç”±æ–¼æ¨¡å‹åˆå§‹åŒ–å¤±æ•—ï¼Œè·³éå¾ŒçºŒæ¸¬è©¦")
        return
    
    # æ¸¬è©¦ 3: Forward pass
    forward_ok = test_forward_pass(model, device, net_config)
    results.append(('Forward Pass', forward_ok))
    
    # æ¸¬è©¦ 4: Backward pass
    backward_ok = test_backward_pass(model, device, net_config)
    results.append(('Backward Pass', backward_ok))
    
    # æ¸¬è©¦ 5: JPEG å™ªè²
    jpeg_ok = test_jpeg_noise(device)
    results.append(('JPEG å™ªè²å±¤', jpeg_ok))
    
    # ç¸½çµ
    print("=" * 60)
    print("æ¸¬è©¦ç¸½çµ")
    print("=" * 60)
    for test_name, passed in results:
        status = "âœ… é€šé" if passed else "âŒ å¤±æ•—"
        print(f"{test_name:.<40} {status}")
    
    all_passed = all(passed for _, passed in results)
    
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼ç¨‹å¼ç¢¼å¯ä»¥æ­£å¸¸é‹è¡Œã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯ã€‚")
    print("=" * 60 + "\n")
    
    # GPU ç›¸å®¹æ€§æç¤º
    print("ğŸ“ æ³¨æ„äº‹é …:")
    print("  - RTX 4090 éœ€è¦ PyTorch 1.13+ æ‰èƒ½ä½¿ç”¨ GPU")
    print("  - ç›®å‰ä½¿ç”¨ CPU æ¨¡å¼é€²è¡Œæ¸¬è©¦")
    print("  - å¦‚éœ€ GPU è¨“ç·´ï¼Œè«‹å‡ç´š PyTorch åˆ° 2.x ç‰ˆæœ¬")
    print()


if __name__ == '__main__':
    main()
