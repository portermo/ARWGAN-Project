# è¨“ç·´æ€§èƒ½å„ªåŒ–å»ºè­°

## ğŸ“Š ç•¶å‰è³‡æºä½¿ç”¨æƒ…æ³ï¼ˆ2026-01-29 15:42ï¼‰

### GPU (NVIDIA GeForce RTX 4090)
- âœ… **GPU åˆ©ç”¨ç‡**: 98-100% (å„ªç§€)
- âš ï¸ **GPU è¨˜æ†¶é«”**: 13.3GB / 24.5GB (54%) - **é‚„æœ‰ 11GB å¯ç”¨ç©ºé–“**
- âœ… **æº«åº¦**: 67Â°C (æ­£å¸¸ç¯„åœ)
- âš ï¸ **åŠŸè€—**: 308W / 450W (é‚„æœ‰ 142W ç©ºé–“)

### CPU (Intel Core i9-14900KF)
- âœ… **CPU æ ¸å¿ƒæ•¸**: 32 æ ¸å¿ƒ
- âš ï¸ **CPU ä½¿ç”¨ç‡**: ä¸»é€²ç¨‹ 100%ï¼Œ4 å€‹ DataLoader worker å„ 5%ï¼Œæ•´é«”ç´„ 3%
- âš ï¸ **DataLoader workers**: 4 å€‹ (å¯å¢åŠ åˆ° 8-16)

### è¨˜æ†¶é«”
- âœ… **ç³»çµ±è¨˜æ†¶é«”**: 57Gi å¯ç”¨ (å……è¶³)
- âœ… **ä¸»é€²ç¨‹è¨˜æ†¶é«”**: 1.1GB (æ­£å¸¸)

---

## ğŸš€ å·²å¯¦æ–½çš„å„ªåŒ–

### 1. DataLoader å„ªåŒ–
å·²æ›´æ–° `watermark_model_better.py` ä¸­çš„ DataLoader é…ç½®ï¼š

```python
# å„ªåŒ–å‰
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)

# å„ªåŒ–å¾Œ
num_workers = min(16, os.cpu_count() or 4)  # è‡ªå‹•èª¿æ•´ worker æ•¸é‡
train_loader = DataLoader(
    train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    num_workers=num_workers,
    pin_memory=True,              # âœ… åŠ é€Ÿ GPU å‚³è¼¸
    persistent_workers=True,        # âœ… é¿å…é‡è¤‡å‰µå»º worker
    prefetch_factor=2              # âœ… é å–2å€‹æ‰¹æ¬¡
)
```

**é æœŸæå‡**: æ•¸æ“šåŠ è¼‰é€Ÿåº¦æå‡ 30-50%

---

## ğŸ’¡ é€²ä¸€æ­¥å„ªåŒ–å»ºè­°

### 1. å¢åŠ  Batch Sizeï¼ˆæ¨è–¦å„ªå…ˆç´šï¼šâ­â­â­â­â­ï¼‰

**ç•¶å‰**: `batch_size=16`  
**å»ºè­°**: `batch_size=24` æˆ– `batch_size=32`

**ç†ç”±**:
- GPU è¨˜æ†¶é«”é‚„æœ‰ 11GB å¯ç”¨ç©ºé–“
- æ›´å¤§çš„ batch size å¯ä»¥ï¼š
  - æå‡ GPU åˆ©ç”¨ç‡
  - åŠ å¿«è¨“ç·´é€Ÿåº¦ï¼ˆæ¯å€‹ epoch æ™‚é–“æ¸›å°‘ï¼‰
  - æé«˜è¨“ç·´ç©©å®šæ€§

**ä½¿ç”¨æ–¹æ³•**:
```bash
# ç•¶å‰å‘½ä»¤
python watermark_model_better.py --train --epochs 10 --batch 16 --data-dir data/coco2017

# å„ªåŒ–å¾Œï¼ˆå»ºè­°ï¼‰
python watermark_model_better.py --train --epochs 10 --batch 24 --data-dir data/coco2017
# æˆ–
python watermark_model_better.py --train --epochs 10 --batch 32 --data-dir data/coco2017
```

**æ³¨æ„**: å¦‚æœå‡ºç¾ CUDA out of memoryï¼Œé€æ­¥é™ä½ batch size

---

### 2. ä½¿ç”¨æ··åˆç²¾åº¦è¨“ç·´ï¼ˆæ¨è–¦å„ªå…ˆç´šï¼šâ­â­â­â­ï¼‰

**å„ªé»**:
- æ¸›å°‘ GPU è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆç´„ 50%ï¼‰
- åŠ å¿«è¨“ç·´é€Ÿåº¦ï¼ˆç´„ 1.5-2xï¼‰
- å…è¨±ä½¿ç”¨æ›´å¤§çš„ batch size

**å¯¦æ–½æ–¹æ³•**: åœ¨è¨“ç·´å¾ªç’°ä¸­æ·»åŠ  `torch.cuda.amp`

---

### 3. å„ªåŒ–æ•¸æ“šåŠ è¼‰ï¼ˆå·²å¯¦æ–½ï¼‰

âœ… **pin_memory=True**: åŠ é€Ÿ CPU åˆ° GPU çš„æ•¸æ“šå‚³è¼¸  
âœ… **persistent_workers=True**: é¿å…æ¯å€‹ epoch é‡è¤‡å‰µå»º worker  
âœ… **prefetch_factor=2**: é å–æ›´å¤šæ‰¹æ¬¡ä»¥æ¸›å°‘ç­‰å¾…æ™‚é–“  
âœ… **num_workers=16**: å……åˆ†åˆ©ç”¨ 32 æ ¸å¿ƒ CPU

---

### 4. æª¢æŸ¥ I/O æ€§èƒ½

å¦‚æœæ•¸æ“šé›†åœ¨æ©Ÿæ¢°ç¡¬ç¢Ÿä¸Šï¼Œè€ƒæ…®ï¼š
- å°‡æ•¸æ“šé›†ç§»åˆ° NVMe SSDï¼ˆå¦‚æœå°šæœªï¼‰
- ä½¿ç”¨ç¬¦è™Ÿé€£çµï¼ˆå·²ä½¿ç”¨ï¼Œå¾ˆå¥½ï¼‰

---

## ğŸ“ˆ é æœŸæ€§èƒ½æå‡

| å„ªåŒ–é …ç›® | é æœŸæå‡ | å¯¦æ–½é›£åº¦ |
|---------|---------|---------|
| å¢åŠ  batch size (16â†’32) | 30-50% | â­ ç°¡å–® |
| DataLoader å„ªåŒ–ï¼ˆå·²å¯¦æ–½ï¼‰ | 30-50% | âœ… å·²å®Œæˆ |
| æ··åˆç²¾åº¦è¨“ç·´ | 50-100% | â­â­ ä¸­ç­‰ |
| **ç¸½é«”é æœŸ** | **2-3x é€Ÿåº¦æå‡** | - |

---

## ğŸ”§ ç«‹å³è¡Œå‹•å»ºè­°

### æ­¥é©Ÿ 1: é‡æ–°å•Ÿå‹•è¨“ç·´ï¼ˆä½¿ç”¨å„ªåŒ–å¾Œçš„ä»£ç¢¼ï¼‰
```bash
# åœæ­¢ç•¶å‰è¨“ç·´ï¼ˆå¦‚æœæ­£åœ¨é‹è¡Œï¼‰
# ç„¶å¾Œä½¿ç”¨å„ªåŒ–å¾Œçš„ä»£ç¢¼é‡æ–°å•Ÿå‹•

cd /mnt/nvme/p3/Project/arwgan/ARWGAN-Project/ARWGAN-main
./run_training.sh --train --epochs 10 --batch 24 --data-dir data/coco2017
```

### æ­¥é©Ÿ 2: ç›£æ§æ€§èƒ½
```bash
# åœ¨å¦ä¸€å€‹çµ‚ç«¯ç›£æ§ GPU
watch -n 1 nvidia-smi

# ç›£æ§ CPU å’Œè¨˜æ†¶é«”
htop
```

### æ­¥é©Ÿ 3: é€æ­¥å¢åŠ  batch size
- å…ˆè©¦ `batch=24`ï¼Œå¦‚æœç©©å®šä¸” GPU è¨˜æ†¶é«” < 20GB
- å†è©¦ `batch=32`ï¼Œå¦‚æœç©©å®šä¸” GPU è¨˜æ†¶é«” < 22GB
- å¦‚æœå‡ºç¾ OOMï¼Œé™ä½åˆ° `batch=20`

---

## ğŸ“ ç•¶å‰è¨“ç·´é€²ç¨‹ç‹€æ…‹

æ ¹æ“š `nvidia-smi` è¼¸å‡ºï¼š
- **ä¸»é€²ç¨‹ PID**: 55116
- **GPU è¨˜æ†¶é«”ä½¿ç”¨**: 13.3GB
- **GPU åˆ©ç”¨ç‡**: 98%
- **è¨“ç·´ç‹€æ…‹**: æ­£åœ¨é‹è¡Œä¸­

**å»ºè­°**: å¦‚æœç•¶å‰è¨“ç·´å·²é€²è¡Œä¸€æ®µæ™‚é–“ï¼Œå¯ä»¥ï¼š
1. è®“ç•¶å‰è¨“ç·´å®Œæˆ
2. ä¸‹æ¬¡è¨“ç·´æ™‚ä½¿ç”¨å„ªåŒ–å¾Œçš„é…ç½®

---

## âš ï¸ æ³¨æ„äº‹é …

1. **Batch Size èª¿æ•´**: å¢åŠ  batch size å¯èƒ½æœƒå½±éŸ¿è¨“ç·´ç©©å®šæ€§ï¼Œå»ºè­°é€æ­¥å¢åŠ 
2. **å­¸ç¿’ç‡èª¿æ•´**: å¦‚æœå¢åŠ  batch sizeï¼Œå¯èƒ½éœ€è¦ç›¸æ‡‰èª¿æ•´å­¸ç¿’ç‡ï¼ˆé€šå¸¸ batch size å¢åŠ  2xï¼Œå­¸ç¿’ç‡ä¹Ÿå¢åŠ  2xï¼‰
3. **è¨˜æ†¶é«”ç›£æ§**: å¯†åˆ‡ç›£æ§ GPU è¨˜æ†¶é«”ä½¿ç”¨ï¼Œé¿å… OOM
4. **æ•¸æ“šåŠ è¼‰**: ç¢ºä¿æ•¸æ“šé›†åœ¨å¿«é€Ÿå­˜å„²è¨­å‚™ä¸Šï¼ˆNVMe SSDï¼‰

---

## ğŸ“ å•é¡Œæ’æŸ¥

å¦‚æœè¨“ç·´é€Ÿåº¦ä»ç„¶æ…¢ï¼Œæª¢æŸ¥ï¼š

1. **æ•¸æ“šåŠ è¼‰ç“¶é ¸**:
   ```bash
   # æª¢æŸ¥ç£ç¢Ÿ I/O
   iostat -x 1
   ```

2. **GPU åˆ©ç”¨ç‡**:
   ```bash
   # æ‡‰è©²æ¥è¿‘ 100%
   nvidia-smi dmon -s u
   ```

3. **CPU ä½¿ç”¨ç‡**:
   ```bash
   # DataLoader workers æ‡‰è©²æœ‰è¼ƒé«˜ä½¿ç”¨ç‡
   htop
   ```

---

**æœ€å¾Œæ›´æ–°**: 2026-01-29 15:42
