# 訓練改進說明：Warm-up 機制和損失權重調整

## 📋 改進內容

### 1. Warm-up 機制 ✅

**目的**：讓 Encoder 和 Decoder 先學習在無干擾的情況下嵌入與提取水印

**實現方式**：
- 前 10 個 epochs：Noise Layer 直接返回原始輸入（無攻擊）
- 第 11 個 epoch 開始：逐漸開啟 Noise Layer 攻擊

**優勢**：
- ✅ 讓模型先掌握基本的水印嵌入和提取能力
- ✅ 避免早期訓練時攻擊干擾導致模型無法學習
- ✅ 提高訓練穩定性和收斂速度

### 2. 損失函數權重調整 ✅

**原配置**：
```python
g_loss = 2.0 * img_loss + 1.0 * wm_loss + 0.001 * g_gan_loss
```

**新配置**：
```python
img_weight = 2.0
wm_weight = 2.0  # 從 1.0 提高到 2.0
gan_weight = 0.001
g_loss = img_weight * img_loss + wm_weight * wm_loss + gan_weight * g_gan_loss
```

**改進**：
- ✅ 將 `wm_loss` 權重從 1.0 提高到 2.0
- ✅ 強迫模型更重視水印準確度
- ✅ 平衡圖像品質和水印提取能力

---

## 🔍 當前訓練狀態分析

根據 `checkpoints_improved/train.csv` 和 `validation.csv`：

### 訓練指標趨勢

| Epoch | G_loss | D_loss | BER (訓練) | PSNR (訓練) | BER (驗證) | PSNR (驗證) | SSIM (驗證) |
|-------|--------|--------|-----------|------------|-----------|------------|------------|
| 1 | -0.4272 | -8.2327 | 0.4991 | 32.61 dB | 0.4983 | 35.73 dB | 0.8985 |
| 2 | 1.0591 | -12.8832 | 0.4990 | 35.64 dB | 0.4988 | 38.74 dB | 0.9120 |
| 3 | 1.2173 | -10.1435 | 0.4992 | 37.48 dB | 0.4994 | 39.18 dB | 0.9290 |
| 4 | 1.2547 | -7.1622 | 0.4990 | 37.54 dB | 0.4991 | 38.59 dB | 0.9550 |
| 5 | 1.0791 | -5.5620 | 0.4985 | 36.91 dB | 0.4974 | 35.41 dB | 0.8159 |
| 6 | 1.0550 | -4.2393 | 0.4869 | 33.25 dB | 0.4741 | 32.20 dB | 0.7309 |

### 問題分析

1. **BER 過高**：
   - 當前 BER ≈ 0.49-0.50（接近隨機猜測 50%）
   - 理想值應該 < 0.01（1%）
   - **說明**：模型傾向於忽略水印，沒有真正學習嵌入

2. **PSNR 良好**：
   - PSNR ≈ 32-39 dB（優秀）
   - **說明**：圖像品質保持良好，但水印提取失敗

3. **SSIM 波動**：
   - SSIM 從 0.96 下降到 0.73
   - **說明**：結構相似性在下降

---

## 💡 改進預期效果

### Warm-up 機制預期效果

**前 10 個 epochs（Warm-up 階段）**：
- ✅ BER 應該快速下降（從 0.50 → 0.10 或更低）
- ✅ 模型學習基本的水印嵌入和提取
- ✅ 訓練更穩定

**第 11 個 epoch 之後（攻擊階段）**：
- ✅ BER 可能會暫時上升（因為開始有攻擊）
- ✅ 但應該比沒有 Warm-up 的情況更好
- ✅ 逐漸適應各種攻擊

### 損失權重調整預期效果

**提高 wm_loss 權重**：
- ✅ BER 應該更快下降
- ✅ 模型更重視水印準確度
- ✅ 可能略微犧牲圖像品質（PSNR 可能下降 1-2 dB）

---

## 🚀 使用改進後的訓練

### 從頭開始訓練（推薦）

```bash
cd /mnt/nvme/p3/Project/arwgan/ARWGAN-Project/ARWGAN-main

./run_training.sh --train \
    --epochs 100 \
    --batch 24 \
    --use_vgg \
    --data-dir data/coco2017 \
    --lr 1e-4
```

**注意**：建議從頭開始訓練以充分利用 Warm-up 機制

### 從檢查點繼續（如果必須）

```bash
./延續訓練_自動檢查點.sh
```

**注意**：如果從檢查點繼續，Warm-up 會根據當前 epoch 自動調整

---

## 📊 監控指標

### 關鍵指標

1. **BER（位元錯誤率）**：
   - Warm-up 階段（前 10 epochs）：應該快速下降
   - 目標：< 0.01（1%）

2. **PSNR（峰值信噪比）**：
   - 應該保持在 > 30 dB
   - 可能因為提高 wm_loss 權重而略微下降

3. **SSIM（結構相似性）**：
   - 應該保持在 > 0.90

### 訓練日誌觀察

訓練時會看到：
```
🔥 Warm-up 階段 (Epoch 1/10): Noise Layer 已關閉，模型學習無干擾的水印嵌入與提取
...
🔥 Warm-up 階段 (Epoch 10/10): Noise Layer 已關閉，模型學習無干擾的水印嵌入與提取
✅ Warm-up 完成！從 Epoch 11 開始啟用 Noise Layer 攻擊
```

---

## ⚙️ 可調整參數

### Warm-up Epochs

如果需要調整 Warm-up 長度，修改 `NoiseLayer` 類：

```python
self.warmup_epochs = 10  # 改為其他值，如 5 或 15
```

### 損失權重

如果需要進一步調整，修改訓練循環中的權重：

```python
img_weight = 2.0    # 圖像品質權重
wm_weight = 2.0     # 水印損失權重（當前已提高）
gan_weight = 0.001  # GAN 對抗損失權重
```

**建議調整**：
- 如果 BER 仍然很高：可以進一步提高 `wm_weight` 到 3.0 或 4.0
- 如果 PSNR 下降太多：可以降低 `wm_weight` 到 1.5

---

## 📈 預期改進

| 指標 | 當前值 | 預期改進後 | 說明 |
|------|--------|-----------|------|
| **BER (無攻擊)** | 0.49 | **< 0.05** | Warm-up 後應該大幅下降 |
| **BER (有攻擊)** | - | **< 0.10** | 攻擊階段應該能保持較低 BER |
| **PSNR** | 32-39 dB | **30-35 dB** | 可能略微下降，但仍在可接受範圍 |
| **訓練穩定性** | 中等 | **高** | Warm-up 提高穩定性 |

---

## 🔧 代碼修改位置

### 1. NoiseLayer 類（Line 187-241）
- 添加 `warmup_epochs` 和 `current_epoch` 屬性
- 添加 `set_epoch()` 方法
- 修改 `forward()` 方法支持 Warm-up

### 2. 訓練循環（Line 733-742）
- 添加 Warm-up 階段提示
- 調用 `noise_layer.set_epoch(epoch)`

### 3. 損失函數（Line 790-795）
- 提高 `wm_weight` 從 1.0 到 2.0
- 使用變量而非硬編碼，方便調整

---

## ✅ 測試結果

Warm-up 機制測試通過：
- ✅ Epoch 0-9：攻擊關閉，輸出等於輸入
- ✅ Epoch 10+：攻擊啟用，輸出有變化

---

**最後更新**: 2026-01-29
